# Dataset-Condensation-with-Gradient-Matching-Considering-Model-Biased-Noise

- 데이터 분석 캡스톤 디자인 프로젝트
- 지도 교수: 이원희

# 주요 내용

- 기계학습에서 주로 사용하는 핵심 데이터셋 선별(Coreset Selection)은 휴리스틱한 요소가 많다는 점과 대표성이 없는 샘플로 데이터셋이 구성되면 최적의 데이터들을 찾지 못하는 문제가 있다. 이러한 문제점을 개선하기 위해 기울기 매칭 알고리즘을 하여 기존 데이터셋을 대표할 새로운 샘플을 합성하는 방법으로 데이터 응축이 소개되었다. 본 논문에서는 기울기 매칭 알고리즘에서 데이터가 복잡해질수록 기울기를 잘 전달하는 모델이 만든 합성 데이터의 성능이 떨어지는 현상을 발견했다. 이러한 문제를 해결하기 위해 기울기를 모델 편향과 데이터 편향 두 부분으로 구분하고 기울기 평균값 매칭, 최댓값 매칭, 기울기 마스킹을 통해 모델 편향을 제거하는 정량적 실험을 수행하였다. 최댓값 매칭을 통해 ResNet, VGG , AlexNet, LeNet, MLP에 대해 0.1~1%의 성능 향상을 보였다. 또한 기울기 마스킹을 통해 전체 기울기의 0.25% 기울기 만으로 88%의 성능을 달성할 수 있음을 보이고 노이즈 제거 비율이 높은 대푯값을 선택할 수록 성능 향상이 있음을 보임으로써 최댓값 매칭의 작동원리를 밝혔다.

# 실행 방법

> !git clone https://github.com/VICO-UoE/DatasetCondensation.git 

- Dataset Condensation 의 원본 코드를 git clone 한다.

<br><br/>
1. (1,1) Pooling 적용
- Average 또는 Max Pooling (1,1) 을 적용할 수 있다.
> main.py 를 (1,1)Pooling_DC.py 로 변경한다.

<br><br/>
2. (2,2) Pooling 적용
- Average 또는 Max Pooling (2,2) 을 적용할 수 있다.
> main.py 를 (2,2)Pooling_DC.py 로 변경한다.

![image](https://user-images.githubusercontent.com/53761548/175493209-b9f5ba1c-70be-41eb-a513-f3f0d52b72d1.png)


<br><br/>
3. Masking 적용
- Masking 을 적용할 수 있다.
> main.py 를 Masking_DC.py 로 변경한다.

# 실험 결과
![image](https://user-images.githubusercontent.com/53761548/175496521-8bd0cc4c-f715-459c-b24c-5c52528c1c14.png)

![image](https://user-images.githubusercontent.com/53761548/175496326-ca47b0c9-45ca-4c38-b2ce-e5f5bca0fc84.png)

![image](https://user-images.githubusercontent.com/53761548/175496350-18c5eb7c-71d4-44ba-9a36-5ecf2d0a230e.png)

![image](https://user-images.githubusercontent.com/53761548/175496361-2d1d0f5f-04e7-4098-9cc9-265f28deb535.png)


- [표 1]에서는 데이터가 단순한 MNIST, Fashion MNIST은 경우 ResNet이 가장 높은 성능을 보였으나 복잡한 데이터로 갈수록 ResNet으로 만든 합성 데이터의 성능이 얕은 층의 모델보다 낮았다. 만약 깊은 층의 모델의 학습과정에서 기울기의 소실과 왜곡이 발생했다면 원본 데이터와 합성 데이터 두 경우 모두에서 얕은 층의 모델에 비해 성능이 낮아야 할 것이다. 그러나 합성 데이터에서만 발생하는 성능 저하는 기울기 자체의 오류보다는 기울기가 개별 모델의 편향적 정보를 강화하는 것이라고 보고 기울기를 모델 편향과 데이터 편향 두 부분으로 나누었다. 

- [표 2,3]는 대푯값 매칭의 결과다. 9개의 가중치에 대해(1,1)은 1개의 대푯값으로 만드는 경우, (2,2)는 4개의 대푯값으로 만드는 경우이다. SVHN, CIFAR10에서 0.1~1%의 성능이 VGG11을 제외한 모든 모델에서 향상되었다. 이는 최댓값 매칭이 노이즈 희석에 효과가 있는 것으로 보인다. 

- [그림 2]는 기울기의 마스킹 분위수를 늘려가며 합성 데이터를 만들어 성능을 측정한 실험 결과다. 위 실험으로 0.25% 이하의 기울기로 전체 기울기를 사용했을 때의 88%의 성능을 낼 수 있음을 발견했다. 이를 통해 전체 기울기 중 소수의 기울기가 합성 데이터의 품질을 결정한다는 것을 알 수 있었다. 또한 해당 실험으로 최댓값이 평균값보다 우위인 이유와 Max(1,1)이 Max(2,2)보다 우위인 이유를 알 수 있었다, 전체 기울기에서 모델 편향적 부분이 99%이상이기 때문에 다량의 노이즈가 섞인 정보의 평균을 구하는 것보다 최댓값을 제외한 나머지 값을 제거하는 것이 더 많은 노이즈를 제거할 수 있기 때문이다. 동일한 관점에서 Max(1,1)은 1개의 대푯값을 Max(2,2)는 4개의 대푯값을 이용하므로 더 많은 노이즈를 제거하기 때문에 우위인 것으로 분석했다.
